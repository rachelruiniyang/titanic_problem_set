{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7412b1e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.030327,
     "end_time": "2023-04-09T13:32:42.484011",
     "exception": false,
     "start_time": "2023-04-09T13:32:42.453684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ad415",
   "metadata": {
    "papermill": {
     "duration": 0.028031,
     "end_time": "2023-04-09T13:32:42.542918",
     "exception": false,
     "start_time": "2023-04-09T13:32:42.514887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50df0fc0",
   "metadata": {
    "papermill": {
     "duration": 0.028674,
     "end_time": "2023-04-09T13:32:42.600096",
     "exception": false,
     "start_time": "2023-04-09T13:32:42.571422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7d1e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:42.658631Z",
     "iopub.status.busy": "2023-04-09T13:32:42.658243Z",
     "iopub.status.idle": "2023-04-09T13:32:43.844858Z",
     "shell.execute_reply": "2023-04-09T13:32:43.843860Z"
    },
    "papermill": {
     "duration": 1.219251,
     "end_time": "2023-04-09T13:32:43.847758",
     "exception": false,
     "start_time": "2023-04-09T13:32:42.628507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c63da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add all hard coded parameters like file paths or model parameters here\n",
    "TRAIN_PATH = \"train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f839a8",
   "metadata": {
    "papermill": {
     "duration": 0.028234,
     "end_time": "2023-04-09T13:32:43.904366",
     "exception": false,
     "start_time": "2023-04-09T13:32:43.876132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f06e7866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:43.963330Z",
     "iopub.status.busy": "2023-04-09T13:32:43.962934Z",
     "iopub.status.idle": "2023-04-09T13:32:43.993431Z",
     "shell.execute_reply": "2023-04-09T13:32:43.992254Z"
    },
    "papermill": {
     "duration": 0.063255,
     "end_time": "2023-04-09T13:32:43.996250",
     "exception": false,
     "start_time": "2023-04-09T13:32:43.932995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "# TODO: Put the path at the top of the script and replace with variable\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f60bc",
   "metadata": {
    "papermill": {
     "duration": 0.028027,
     "end_time": "2023-04-09T13:32:44.052623",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.024596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preliminary data inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26354e31",
   "metadata": {
    "papermill": {
     "duration": 0.028388,
     "end_time": "2023-04-09T13:32:44.110277",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.081889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Quick glimpse of the data\n",
    "TODO: Think if you can abstract away much here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80c7cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:44.169495Z",
     "iopub.status.busy": "2023-04-09T13:32:44.168457Z",
     "iopub.status.idle": "2023-04-09T13:32:44.199987Z",
     "shell.execute_reply": "2023-04-09T13:32:44.198640Z"
    },
    "papermill": {
     "duration": 0.06465,
     "end_time": "2023-04-09T13:32:44.203227",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.138577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae57c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:44.262736Z",
     "iopub.status.busy": "2023-04-09T13:32:44.262340Z",
     "iopub.status.idle": "2023-04-09T13:32:44.279048Z",
     "shell.execute_reply": "2023-04-09T13:32:44.277660Z"
    },
    "papermill": {
     "duration": 0.049372,
     "end_time": "2023-04-09T13:32:44.281443",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.232071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc9caf0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:44.340970Z",
     "iopub.status.busy": "2023-04-09T13:32:44.340538Z",
     "iopub.status.idle": "2023-04-09T13:32:44.365388Z",
     "shell.execute_reply": "2023-04-09T13:32:44.364117Z"
    },
    "papermill": {
     "duration": 0.05775,
     "end_time": "2023-04-09T13:32:44.368073",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.310323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd509493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:44.428455Z",
     "iopub.status.busy": "2023-04-09T13:32:44.428047Z",
     "iopub.status.idle": "2023-04-09T13:32:44.442892Z",
     "shell.execute_reply": "2023-04-09T13:32:44.441210Z"
    },
    "papermill": {
     "duration": 0.048578,
     "end_time": "2023-04-09T13:32:44.445514",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.396936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d25a33b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:44.507385Z",
     "iopub.status.busy": "2023-04-09T13:32:44.506106Z",
     "iopub.status.idle": "2023-04-09T13:32:44.545280Z",
     "shell.execute_reply": "2023-04-09T13:32:44.543818Z"
    },
    "papermill": {
     "duration": 0.073749,
     "end_time": "2023-04-09T13:32:44.548724",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.474975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3af70a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:44.612980Z",
     "iopub.status.busy": "2023-04-09T13:32:44.612542Z",
     "iopub.status.idle": "2023-04-09T13:32:44.643947Z",
     "shell.execute_reply": "2023-04-09T13:32:44.642555Z"
    },
    "papermill": {
     "duration": 0.066018,
     "end_time": "2023-04-09T13:32:44.646541",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.580523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
       "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb886bb0",
   "metadata": {
    "papermill": {
     "duration": 0.029351,
     "end_time": "2023-04-09T13:32:44.706536",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.677185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Few statistics on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97cad3",
   "metadata": {
    "papermill": {
     "duration": 0.029214,
     "end_time": "2023-04-09T13:32:44.766549",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.737335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d0dd3ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:44.898581Z",
     "iopub.status.busy": "2023-04-09T13:32:44.897545Z",
     "iopub.status.idle": "2023-04-09T13:32:44.920932Z",
     "shell.execute_reply": "2023-04-09T13:32:44.919700Z"
    },
    "papermill": {
     "duration": 0.057738,
     "end_time": "2023-04-09T13:32:44.924016",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.866278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "total = train_df.isnull().sum()\n",
    "percent = (train_df.isnull().sum()/train_df.isnull().count()*100)\n",
    "tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "types = []\n",
    "for col in train_df.columns:\n",
    "    dtype = str(train_df[col].dtype)\n",
    "    types.append(dtype)\n",
    "tt['Types'] = types\n",
    "df_missing_train = np.transpose(tt)\n",
    "\n",
    "####\n",
    "def missing_data_summary(df):\n",
    "    \"\"\"\n",
    "    Generate a summary of missing data in the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.dataframe): The dataframe to analyze.\n",
    "\n",
    "    Returns:\n",
    "    pd.dataframe: A dataframe summarizing the total and percentage of missing values\n",
    "                  and the data types of each column.\n",
    "    \"\"\"\n",
    "    total = df.isnull().sum()\n",
    "    percent = (df.isnull().sum() / df.count() * 100)  # Use df.count() instead of isnull().count()\n",
    "    summary = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    \n",
    "    # Getting the data types\n",
    "    summary['Types'] = df.dtypes.values  # Get data types directly from the DataFrame\n",
    "    \n",
    "    # Transpose the summary DataFrame for better readability\n",
    "    return summary.transpose()\n",
    "\n",
    "# Example usage:\n",
    "# df_missing_train = missing_data_summary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c372cbd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:44.986374Z",
     "iopub.status.busy": "2023-04-09T13:32:44.985655Z",
     "iopub.status.idle": "2023-04-09T13:32:45.011350Z",
     "shell.execute_reply": "2023-04-09T13:32:45.010181Z"
    },
    "papermill": {
     "duration": 0.05972,
     "end_time": "2023-04-09T13:32:45.014135",
     "exception": false,
     "start_time": "2023-04-09T13:32:44.954415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "total = test_df.isnull().sum()\n",
    "percent = (test_df.isnull().sum()/test_df.isnull().count()*100)\n",
    "tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "types = []\n",
    "for col in test_df.columns:\n",
    "    dtype = str(test_df[col].dtype)\n",
    "    types.append(dtype)\n",
    "tt['Types'] = types\n",
    "df_missing_test = np.transpose(tt)\n",
    "\n",
    "####\n",
    "def missing_data_summary(df):\n",
    "    \"\"\"\n",
    "    Generate a summary of missing data in the dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.dataframe): The dataframe to analyze.\n",
    "\n",
    "    Returns:\n",
    "    pd.dataframe: A dataframe summarizing the total and percentage of missing values\n",
    "                  and the data types of each column.\n",
    "    \"\"\"\n",
    "    total = df.isnull().sum()\n",
    "    percent = (df.isnull().sum() / df.count() * 100)  # Use df.count() for non-null counts\n",
    "    summary = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    \n",
    "    # Getting the data types\n",
    "    types = [str(df[col].dtype) for col in df.columns]\n",
    "    summary['Types'] = types\n",
    "    \n",
    "    # Transpose the summary DataFrame for better readability\n",
    "    return summary.transpose()\n",
    "\n",
    "# Example usage:\n",
    "# df_missing_test = missing_data_summary(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5109172",
   "metadata": {
    "papermill": {
     "duration": 0.029638,
     "end_time": "2023-04-09T13:32:45.074364",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.044726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Most frequent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eebf73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:45.209562Z",
     "iopub.status.busy": "2023-04-09T13:32:45.208882Z",
     "iopub.status.idle": "2023-04-09T13:32:45.243467Z",
     "shell.execute_reply": "2023-04-09T13:32:45.242558Z"
    },
    "papermill": {
     "duration": 0.068629,
     "end_time": "2023-04-09T13:32:45.245938",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.177309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "total = train_df.count()\n",
    "tt = pd.DataFrame(total)\n",
    "tt.columns = ['Total']\n",
    "items = []\n",
    "vals = []\n",
    "for col in train_df.columns:\n",
    "    try:\n",
    "        itm = train_df[col].value_counts().index[0]\n",
    "        val = train_df[col].value_counts().values[0]\n",
    "        items.append(itm)\n",
    "        vals.append(val)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        items.append(0)\n",
    "        vals.append(0)\n",
    "        continue\n",
    "tt['Most frequent item'] = items\n",
    "tt['Frequence'] = vals\n",
    "tt['Percent from total'] = np.round(vals / total * 100, 3)\n",
    "np.transpose(tt)\n",
    "\n",
    "#### \n",
    "\n",
    "def frequency_summary(df):\n",
    "    \"\"\"\n",
    "    Generate a summary of the frequency of the most common item in each column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame summarizing the most frequent item, its frequency, \n",
    "                  and the percentage from the total for each column.\n",
    "    \"\"\"\n",
    "    total = df.count()  # Count of non-null values per column\n",
    "    summary = pd.DataFrame(total, columns=['Total'])\n",
    "\n",
    "    items = []\n",
    "    vals = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            itm = df[col].value_counts().index[0]  # Most frequent item\n",
    "            val = df[col].value_counts().values[0]  # Frequency of the most frequent item\n",
    "        except Exception as ex:\n",
    "            print(f\"Error processing column {col}: {ex}\")\n",
    "            itm, val = 0, 0  # In case there's an exception, default to 0\n",
    "        items.append(itm)\n",
    "        vals.append(val)\n",
    "\n",
    "    summary['Most frequent item'] = items\n",
    "    summary['Frequence'] = vals\n",
    "    summary['Percent from total'] = np.round(np.array(vals) / total * 100, 3)\n",
    "\n",
    "    # Transpose the summary for better readability\n",
    "    return summary.transpose()\n",
    "\n",
    "# Example usage:\n",
    "# df_frequency_train = frequency_summary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f41e5126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:45.308398Z",
     "iopub.status.busy": "2023-04-09T13:32:45.307969Z",
     "iopub.status.idle": "2023-04-09T13:32:45.338304Z",
     "shell.execute_reply": "2023-04-09T13:32:45.336857Z"
    },
    "papermill": {
     "duration": 0.065008,
     "end_time": "2023-04-09T13:32:45.340867",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.275859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "total = test_df.count()\n",
    "tt = pd.DataFrame(total)\n",
    "tt.columns = ['Total']\n",
    "items = []\n",
    "vals = []\n",
    "for col in test_df.columns:\n",
    "    try:\n",
    "        itm = test_df[col].value_counts().index[0]\n",
    "        val = test_df[col].value_counts().values[0]\n",
    "        items.append(itm)\n",
    "        vals.append(val)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        items.append(0)\n",
    "        vals.append(0)\n",
    "        continue\n",
    "tt['Most frequent item'] = items\n",
    "tt['Frequence'] = vals\n",
    "tt['Percent from total'] = np.round(vals / total * 100, 3)\n",
    "np.transpose(tt)\n",
    "\n",
    "def frequency_summary(df):\n",
    "    \"\"\"\n",
    "    Generate a summary of the frequency of the most common item in each column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame summarizing the most frequent item, its frequency, \n",
    "                  and the percentage from the total for each column.\n",
    "    \"\"\"\n",
    "    total = df.count()  # Count of non-null values per column\n",
    "    summary = pd.DataFrame(total, columns=['Total'])\n",
    "\n",
    "    items = []\n",
    "    vals = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            itm = df[col].value_counts().index[0]  # Most frequent item\n",
    "            val = df[col].value_counts().values[0]  # Frequency of the most frequent item\n",
    "        except Exception as ex:\n",
    "            print(f\"Error processing column {col}: {ex}\")\n",
    "            itm, val = 0, 0  # In case of an error, default to 0\n",
    "        items.append(itm)\n",
    "        vals.append(val)\n",
    "\n",
    "    summary['Most frequent item'] = items\n",
    "    summary['Frequence'] = vals\n",
    "    summary['Percent from total'] = np.round(np.array(vals) / total * 100, 3)\n",
    "\n",
    "    # Transpose the summary for better readability\n",
    "    return summary.transpose()\n",
    "\n",
    "# Example usage:\n",
    "# df_frequency_test = frequency_summary(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d18c8b",
   "metadata": {
    "papermill": {
     "duration": 0.029988,
     "end_time": "2023-04-09T13:32:45.401178",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.371190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f09fd047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:45.463926Z",
     "iopub.status.busy": "2023-04-09T13:32:45.463429Z",
     "iopub.status.idle": "2023-04-09T13:32:45.469932Z",
     "shell.execute_reply": "2023-04-09T13:32:45.469031Z"
    },
    "papermill": {
     "duration": 0.040924,
     "end_time": "2023-04-09T13:32:45.472353",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.431429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "total = train_df.count()\n",
    "tt = pd.DataFrame(total)\n",
    "tt.columns = ['Total']\n",
    "uniques = []\n",
    "for col in train_df.columns:\n",
    "    unique = train_df[col].nunique()\n",
    "    uniques.append(unique)\n",
    "tt['Uniques'] = uniques\n",
    "np.transpose(tt)\n",
    "\n",
    "def unique_values_summary(df):\n",
    "    \"\"\"\n",
    "    Generate a summary of the total and unique values for each column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame summarizing the total count and number of unique values\n",
    "                  for each column.\n",
    "    \"\"\"\n",
    "    total = df.count()  # Count of non-null values per column\n",
    "    summary = pd.DataFrame(total, columns=['Total'])\n",
    "\n",
    "    uniques = [df[col].nunique() for col in df.columns]  # Number of unique values per column\n",
    "    summary['Uniques'] = uniques\n",
    "\n",
    "    # Transpose the summary DataFrame for better readability\n",
    "    return summary.transpose()\n",
    "\n",
    "# Example usage:\n",
    "# df_unique_train = unique_values_summary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225a84a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:45.536435Z",
     "iopub.status.busy": "2023-04-09T13:32:45.535529Z",
     "iopub.status.idle": "2023-04-09T13:32:45.556243Z",
     "shell.execute_reply": "2023-04-09T13:32:45.554903Z"
    },
    "papermill": {
     "duration": 0.055267,
     "end_time": "2023-04-09T13:32:45.559112",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.503845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "total = test_df.count()\n",
    "tt = pd.DataFrame(total)\n",
    "tt.columns = ['Total']\n",
    "uniques = []\n",
    "for col in test_df.columns:\n",
    "    unique = test_df[col].nunique()\n",
    "    uniques.append(unique)\n",
    "tt['Uniques'] = uniques\n",
    "np.transpose(tt)\n",
    "\n",
    "def unique_values_summary(df):\n",
    "    \"\"\"\n",
    "    Generate a summary of the total and unique values for each column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to analyze.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame summarizing the total count and number of unique values\n",
    "                  for each column.\n",
    "    \"\"\"\n",
    "    total = df.count()  # Count of non-null values per column\n",
    "    summary = pd.DataFrame(total, columns=['Total'])\n",
    "\n",
    "    uniques = [df[col].nunique() for col in df.columns]  # Number of unique values per column\n",
    "    summary['Uniques'] = uniques\n",
    "\n",
    "    # Transpose the summary DataFrame for better readability\n",
    "    return summary.transpose()\n",
    "\n",
    "# Example usage:\n",
    "# df_unique_test = unique_values_summary(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3b074",
   "metadata": {
    "papermill": {
     "duration": 0.031049,
     "end_time": "2023-04-09T13:32:45.711070",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.680021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b05f1",
   "metadata": {
    "papermill": {
     "duration": 0.030333,
     "end_time": "2023-04-09T13:32:45.773288",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.742955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Univariate analysis for all features\n",
    "\n",
    "\n",
    "We show here two graphs in paralel:\n",
    "* distribution of class values, split per Survived value\n",
    "* comparison of class values, in train and test data\n",
    "\n",
    "\n",
    "Let's first aggregate train and test data into one single dataframe, `all_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "400dcbcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:45.837448Z",
     "iopub.status.busy": "2023-04-09T13:32:45.836771Z",
     "iopub.status.idle": "2023-04-09T13:32:45.847099Z",
     "shell.execute_reply": "2023-04-09T13:32:45.845835Z"
    },
    "papermill": {
     "duration": 0.045321,
     "end_time": "2023-04-09T13:32:45.849857",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.804536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "all_df = pd.concat([train_df, test_df], axis=0)\n",
    "all_df[\"set\"] = \"train\"\n",
    "all_df.loc[all_df.Survived.isna(), \"set\"] = \"test\"\n",
    "\n",
    "\n",
    "def combine_train_test(train_df, test_df, target_col):\n",
    "    \"\"\"\n",
    "    Combine the train and test DataFrames, and label the rows based on the dataset they belong to.\n",
    "\n",
    "    Parameters:\n",
    "    train_df (pd.DataFrame): The training DataFrame.\n",
    "    test_df (pd.DataFrame): The testing DataFrame.\n",
    "    target_col (str): The target column that indicates the training label (e.g., 'Survived').\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame combining both train and test data, with an additional 'set' column.\n",
    "    \"\"\"\n",
    "    # Concatenate train and test DataFrames\n",
    "    all_df = pd.concat([train_df, test_df], axis=0)\n",
    "    \n",
    "    # Label all rows as 'train'\n",
    "    all_df[\"set\"] = \"train\"\n",
    "    \n",
    "    # Label rows as 'test' where the target column is NaN (i.e., they belong to the test set)\n",
    "    all_df.loc[all_df[target_col].isna(), \"set\"] = \"test\"\n",
    "    \n",
    "    return all_df\n",
    "\n",
    "# Example usage:\n",
    "# combined_df = combine_train_test(train_df, test_df, 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30801ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:45.913767Z",
     "iopub.status.busy": "2023-04-09T13:32:45.913366Z",
     "iopub.status.idle": "2023-04-09T13:32:45.932505Z",
     "shell.execute_reply": "2023-04-09T13:32:45.931173Z"
    },
    "papermill": {
     "duration": 0.054358,
     "end_time": "2023-04-09T13:32:45.935425",
     "exception": false,
     "start_time": "2023-04-09T13:32:45.881067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked    set  \n",
       "0      0         A/5 21171   7.2500   NaN        S  train  \n",
       "1      0          PC 17599  71.2833   C85        C  train  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  train  \n",
       "3      0            113803  53.1000  C123        S  train  \n",
       "4      0            373450   8.0500   NaN        S  train  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63514a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot count pairs \"Sex\"\n",
    "f, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "sns.countplot(x=\"Sex\", data=all_df, hue=\"set\", palette= color_list)\n",
    "plt.grid(color=\"black\", linestyle=\"-.\", linewidth=0.5, axis=\"y\", which=\"major\")\n",
    "ax.set_title(\"Number of passengers / Sex\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d14ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution pairs for \"Sex\" and hue as \"Survived\"\n",
    "color_list = [\"#A5D7E8\", \"#576CBC\", \"#19376D\", \"#0b2447\"]\n",
    "f, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "for i, h in enumerate(train_df[\"Survived\"].unique()):\n",
    "    g = sns.histplot(train_df.loc[train_df[\"Survived\"]==h, \"Sex\"], \n",
    "                                  color=color_list[i], \n",
    "                                  ax=ax, \n",
    "                                  label=h)\n",
    "ax.set_title(\"Number of passengers / Sex\")\n",
    "g.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b7b1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:46.501255Z",
     "iopub.status.busy": "2023-04-09T13:32:46.500379Z",
     "iopub.status.idle": "2023-04-09T13:32:46.738315Z",
     "shell.execute_reply": "2023-04-09T13:32:46.737065Z"
    },
    "papermill": {
     "duration": 0.273785,
     "end_time": "2023-04-09T13:32:46.741101",
     "exception": false,
     "start_time": "2023-04-09T13:32:46.467316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot count pairs using all_df for the columns: Sex, Pclasss, SibSp, Parch, Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot count pairs using all_df for the columns: Sex, Pclasss, SibSp, Parch, Embarked and use \"Survived\" as hue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc36b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution pairs for Age and Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8cccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution pairs for Age and Fare using \"Survived\" as hue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b45219",
   "metadata": {
    "papermill": {
     "duration": 0.037641,
     "end_time": "2023-04-09T13:32:52.114502",
     "exception": false,
     "start_time": "2023-04-09T13:32:52.076861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Family size\n",
    "\n",
    "\n",
    "Based on SibSp (sibilings or spouse) and Parch (parents or children), we set the Family Size field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5836df98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:52.192880Z",
     "iopub.status.busy": "2023-04-09T13:32:52.192410Z",
     "iopub.status.idle": "2023-04-09T13:32:52.198908Z",
     "shell.execute_reply": "2023-04-09T13:32:52.197822Z"
    },
    "papermill": {
     "duration": 0.048281,
     "end_time": "2023-04-09T13:32:52.201022",
     "exception": false,
     "start_time": "2023-04-09T13:32:52.152741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "all_df[\"Family Size\"] = all_df[\"SibSp\"] + all_df[\"Parch\"] + 1\n",
    "\n",
    "def add_family_size(df, sibsp_col='SibSp', parch_col='Parch'):\n",
    "    \"\"\"\n",
    "    Add a 'Family Size' column to the DataFrame based on the number of siblings/spouses\n",
    "    and parents/children aboard, plus one for the individual.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to add the 'Family Size' column to.\n",
    "    sibsp_col (str): The name of the column representing siblings/spouses aboard. Default is 'SibSp'.\n",
    "    parch_col (str): The name of the column representing parents/children aboard. Default is 'Parch'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with an added 'Family Size' column.\n",
    "    \"\"\"\n",
    "    df[\"Family Size\"] = df[sibsp_col] + df[parch_col] + 1\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# combined_df = add_family_size(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31e7eb6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:52.279230Z",
     "iopub.status.busy": "2023-04-09T13:32:52.278523Z",
     "iopub.status.idle": "2023-04-09T13:32:52.284255Z",
     "shell.execute_reply": "2023-04-09T13:32:52.283378Z"
    },
    "papermill": {
     "duration": 0.04778,
     "end_time": "2023-04-09T13:32:52.286848",
     "exception": false,
     "start_time": "2023-04-09T13:32:52.239068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "train_df[\"Family Size\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\n",
    "### \n",
    "def add_family_size(df, sibsp_col='SibSp', parch_col='Parch'):\n",
    "    \"\"\"\n",
    "    Add a 'Family Size' column to the DataFrame based on the number of siblings/spouses\n",
    "    and parents/children aboard, plus one for the individual.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to add the 'Family Size' column to.\n",
    "    sibsp_col (str): The name of the column representing siblings/spouses aboard. Default is 'SibSp'.\n",
    "    parch_col (str): The name of the column representing parents/children aboard. Default is 'Parch'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with an added 'Family Size' column.\n",
    "    \"\"\"\n",
    "    df[\"Family Size\"] = df[sibsp_col] + df[parch_col] + 1\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# train_df = add_family_size(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c01cdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:52.740841Z",
     "iopub.status.busy": "2023-04-09T13:32:52.739684Z",
     "iopub.status.idle": "2023-04-09T13:32:53.041356Z",
     "shell.execute_reply": "2023-04-09T13:32:53.039962Z"
    },
    "papermill": {
     "duration": 0.345277,
     "end_time": "2023-04-09T13:32:53.044264",
     "exception": false,
     "start_time": "2023-04-09T13:32:52.698987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot count pairs using all_df for the column \"Family Size\" and use \"Survived\" as hue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deb3497",
   "metadata": {
    "papermill": {
     "duration": 0.039742,
     "end_time": "2023-04-09T13:32:53.124517",
     "exception": false,
     "start_time": "2023-04-09T13:32:53.084775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Age interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3f2cc96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:53.206624Z",
     "iopub.status.busy": "2023-04-09T13:32:53.205765Z",
     "iopub.status.idle": "2023-04-09T13:32:53.218451Z",
     "shell.execute_reply": "2023-04-09T13:32:53.217502Z"
    },
    "papermill": {
     "duration": 0.056998,
     "end_time": "2023-04-09T13:32:53.221006",
     "exception": false,
     "start_time": "2023-04-09T13:32:53.164008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "all_df[\"Age Interval\"] = 0.0\n",
    "all_df.loc[ all_df['Age'] <= 16, 'Age Interval']  = 0\n",
    "all_df.loc[(all_df['Age'] > 16) & (all_df['Age'] <= 32), 'Age Interval'] = 1\n",
    "all_df.loc[(all_df['Age'] > 32) & (all_df['Age'] <= 48), 'Age Interval'] = 2\n",
    "all_df.loc[(all_df['Age'] > 48) & (all_df['Age'] <= 64), 'Age Interval'] = 3\n",
    "all_df.loc[ all_df['Age'] > 64, 'Age Interval'] = 4\n",
    "\n",
    "####\n",
    "def add_age_interval(df, age_col='Age'):\n",
    "    \"\"\"\n",
    "    Add an 'Age Interval' column to the DataFrame, categorizing ages into intervals.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to add the 'Age Interval' column to.\n",
    "    age_col (str): The name of the column representing age. Default is 'Age'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with an added 'Age Interval' column.\n",
    "    \"\"\"\n",
    "    # Initialize the 'Age Interval' column with default values\n",
    "    df[\"Age Interval\"] = 0.0\n",
    "    \n",
    "    # Apply conditions to assign age intervals\n",
    "    df.loc[df[age_col] <= 16, 'Age Interval'] = 0\n",
    "    df.loc[(df[age_col] > 16) & (df[age_col] <= 32), 'Age Interval'] = 1\n",
    "    df.loc[(df[age_col] > 32) & (df[age_col] <= 48), 'Age Interval'] = 2\n",
    "    df.loc[(df[age_col] > 48) & (df[age_col] <= 64), 'Age Interval'] = 3\n",
    "    df.loc[df[age_col] > 64, 'Age Interval'] = 4\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# all_df = add_age_interval(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34983e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:53.303008Z",
     "iopub.status.busy": "2023-04-09T13:32:53.302250Z",
     "iopub.status.idle": "2023-04-09T13:32:53.314396Z",
     "shell.execute_reply": "2023-04-09T13:32:53.313309Z"
    },
    "papermill": {
     "duration": 0.055966,
     "end_time": "2023-04-09T13:32:53.317052",
     "exception": false,
     "start_time": "2023-04-09T13:32:53.261086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "train_df[\"Age Interval\"] = 0.0\n",
    "train_df.loc[train_df['Age'] <= 16, 'Age Interval']  = 0\n",
    "train_df.loc[(train_df['Age'] > 16) & (train_df['Age'] <= 32), 'Age Interval'] = 1\n",
    "train_df.loc[(train_df['Age'] > 32) & (train_df['Age'] <= 48), 'Age Interval'] = 2\n",
    "train_df.loc[(train_df['Age'] > 48) & (train_df['Age'] <= 64), 'Age Interval'] = 3\n",
    "train_df.loc[ train_df['Age'] > 64, 'Age Interval'] = 4\n",
    "\n",
    "def add_age_interval(df, age_col='Age'):\n",
    "    \"\"\"\n",
    "    Add an 'Age Interval' column to the DataFrame, categorizing ages into intervals.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to add the 'Age Interval' column to.\n",
    "    age_col (str): The name of the column representing age. Default is 'Age'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with an added 'Age Interval' column.\n",
    "    \"\"\"\n",
    "    # Initialize the 'Age Interval' column with default values\n",
    "    df[\"Age Interval\"] = 0.0\n",
    "    \n",
    "    # Apply conditions to assign age intervals\n",
    "    df.loc[df[age_col] <= 16, 'Age Interval'] = 0\n",
    "    df.loc[(df[age_col] > 16) & (df[age_col] <= 32), 'Age Interval'] = 1\n",
    "    df.loc[(df[age_col] > 32) & (df[age_col] <= 48), 'Age Interval'] = 2\n",
    "    df.loc[(df[age_col] > 48) & (df[age_col] <= 64), 'Age Interval'] = 3\n",
    "    df.loc[df[age_col] > 64, 'Age Interval'] = 4\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# train_df = add_age_interval(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e3cf35b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:53.399536Z",
     "iopub.status.busy": "2023-04-09T13:32:53.398814Z",
     "iopub.status.idle": "2023-04-09T13:32:53.419682Z",
     "shell.execute_reply": "2023-04-09T13:32:53.418372Z"
    },
    "papermill": {
     "duration": 0.066082,
     "end_time": "2023-04-09T13:32:53.422448",
     "exception": false,
     "start_time": "2023-04-09T13:32:53.356366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked    set  \n",
       "0      0         A/5 21171   7.2500   NaN        S  train  \n",
       "1      0          PC 17599  71.2833   C85        C  train  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  train  \n",
       "3      0            113803  53.1000  C123        S  train  \n",
       "4      0            373450   8.0500   NaN        S  train  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eed6de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:53.857101Z",
     "iopub.status.busy": "2023-04-09T13:32:53.856605Z",
     "iopub.status.idle": "2023-04-09T13:32:54.064894Z",
     "shell.execute_reply": "2023-04-09T13:32:54.063559Z"
    },
    "papermill": {
     "duration": 0.254066,
     "end_time": "2023-04-09T13:32:54.068054",
     "exception": false,
     "start_time": "2023-04-09T13:32:53.813988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot count pairs using all_df for the column \"Age Interval\" and use \"Survived\" as hue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f76d4",
   "metadata": {
    "papermill": {
     "duration": 0.040927,
     "end_time": "2023-04-09T13:32:54.149697",
     "exception": false,
     "start_time": "2023-04-09T13:32:54.108770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fare interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a006b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:54.234868Z",
     "iopub.status.busy": "2023-04-09T13:32:54.233763Z",
     "iopub.status.idle": "2023-04-09T13:32:54.245013Z",
     "shell.execute_reply": "2023-04-09T13:32:54.243861Z"
    },
    "papermill": {
     "duration": 0.056119,
     "end_time": "2023-04-09T13:32:54.247557",
     "exception": false,
     "start_time": "2023-04-09T13:32:54.191438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "all_df['Fare Interval'] = 0.0\n",
    "all_df.loc[ all_df['Fare'] <= 7.91, 'Fare Interval'] = 0\n",
    "all_df.loc[(all_df['Fare'] > 7.91) & (all_df['Fare'] <= 14.454), 'Fare Interval'] = 1\n",
    "all_df.loc[(all_df['Fare'] > 14.454) & (all_df['Fare'] <= 31), 'Fare Interval']   = 2\n",
    "all_df.loc[ all_df['Fare'] > 31, 'Fare Interval'] = 3\n",
    "\n",
    "def add_fare_interval_column(df):\n",
    "    \"\"\"\n",
    "    Add a 'Fare Interval' column to the DataFrame based on fare ranges.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the 'Fare' column.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with the added 'Fare Interval' column.\n",
    "    \"\"\"\n",
    "    df['Fare Interval'] = 0.0\n",
    "    df.loc[df['Fare'] <= 7.91, 'Fare Interval'] = 0\n",
    "    df.loc[(df['Fare'] > 7.91) & (df['Fare'] <= 14.454), 'Fare Interval'] = 1\n",
    "    df.loc[(df['Fare'] > 14.454) & (df['Fare'] <= 31), 'Fare Interval'] = 2\n",
    "    df.loc[df['Fare'] > 31, 'Fare Interval'] = 3\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "650276ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:54.332150Z",
     "iopub.status.busy": "2023-04-09T13:32:54.331087Z",
     "iopub.status.idle": "2023-04-09T13:32:54.342077Z",
     "shell.execute_reply": "2023-04-09T13:32:54.340822Z"
    },
    "papermill": {
     "duration": 0.05683,
     "end_time": "2023-04-09T13:32:54.345078",
     "exception": false,
     "start_time": "2023-04-09T13:32:54.288248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "train_df['Fare Interval'] = 0.0\n",
    "train_df.loc[ train_df['Fare'] <= 7.91, 'Fare Interval'] = 0\n",
    "train_df.loc[(train_df['Fare'] > 7.91) & (train_df['Fare'] <= 14.454), 'Fare Interval'] = 1\n",
    "train_df.loc[(train_df['Fare'] > 14.454) & (train_df['Fare'] <= 31), 'Fare Interval']   = 2\n",
    "train_df.loc[ train_df['Fare'] > 31, 'Fare Interval'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366baba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:54.430960Z",
     "iopub.status.busy": "2023-04-09T13:32:54.430168Z",
     "iopub.status.idle": "2023-04-09T13:32:54.610581Z",
     "shell.execute_reply": "2023-04-09T13:32:54.609578Z"
    },
    "papermill": {
     "duration": 0.226435,
     "end_time": "2023-04-09T13:32:54.613085",
     "exception": false,
     "start_time": "2023-04-09T13:32:54.386650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot count pairs using all_df for the column \"Fare Interval\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc5973",
   "metadata": {
    "papermill": {
     "duration": 0.041281,
     "end_time": "2023-04-09T13:32:54.696212",
     "exception": false,
     "start_time": "2023-04-09T13:32:54.654931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's create a composed feature: Pclass + Sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dde69195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:54.782311Z",
     "iopub.status.busy": "2023-04-09T13:32:54.781868Z",
     "iopub.status.idle": "2023-04-09T13:32:54.807048Z",
     "shell.execute_reply": "2023-04-09T13:32:54.805726Z"
    },
    "papermill": {
     "duration": 0.071099,
     "end_time": "2023-04-09T13:32:54.809961",
     "exception": false,
     "start_time": "2023-04-09T13:32:54.738862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "train_df[\"Sex_Pclass\"] = train_df.apply(lambda row: row['Sex'][0].upper() + \"_C\" + str(row[\"Pclass\"]), axis=1)\n",
    "\n",
    "def add_sex_pclass(df, sex_col='Sex', pclass_col='Pclass'):\n",
    "    \"\"\"\n",
    "    Add a 'Sex_Pclass' column to the DataFrame, combining the first letter of 'Sex' \n",
    "    and the 'Pclass' with a specific format.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to add the 'Sex_Pclass' column to.\n",
    "    sex_col (str): The name of the column representing sex. Default is 'Sex'.\n",
    "    pclass_col (str): The name of the column representing passenger class. Default is 'Pclass'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with an added 'Sex_Pclass' column.\n",
    "    \"\"\"\n",
    "    df[\"Sex_Pclass\"] = df.apply(lambda row: row[sex_col][0].upper() + \"_C\" + str(row[pclass_col]), axis=1)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# train_df = add_sex_pclass(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd550332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:54.895821Z",
     "iopub.status.busy": "2023-04-09T13:32:54.895374Z",
     "iopub.status.idle": "2023-04-09T13:32:54.924406Z",
     "shell.execute_reply": "2023-04-09T13:32:54.923166Z"
    },
    "papermill": {
     "duration": 0.076071,
     "end_time": "2023-04-09T13:32:54.927112",
     "exception": false,
     "start_time": "2023-04-09T13:32:54.851041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "all_df[\"Sex_Pclass\"] = all_df.apply(lambda row: row['Sex'][0].upper() + \"_C\" + str(row[\"Pclass\"]), axis=1)\n",
    "\n",
    "####\n",
    "def add_sex_pclass(df, sex_col='Sex', pclass_col='Pclass'):\n",
    "    \"\"\"\n",
    "    Add a 'Sex_Pclass' column to the DataFrame, combining the first letter of 'Sex' \n",
    "    and the 'Pclass' with a specific format.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to add the 'Sex_Pclass' column to.\n",
    "    sex_col (str): The name of the column representing sex. Default is 'Sex'.\n",
    "    pclass_col (str): The name of the column representing passenger class. Default is 'Pclass'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with an added 'Sex_Pclass' column.\n",
    "    \"\"\"\n",
    "    df[\"Sex_Pclass\"] = df.apply(lambda row: row[sex_col][0].upper() + \"_C\" + str(row[pclass_col]), axis=1)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# all_df = add_sex_pclass(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63ef42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:55.012451Z",
     "iopub.status.busy": "2023-04-09T13:32:55.012004Z",
     "iopub.status.idle": "2023-04-09T13:32:55.269357Z",
     "shell.execute_reply": "2023-04-09T13:32:55.268465Z"
    },
    "papermill": {
     "duration": 0.302947,
     "end_time": "2023-04-09T13:32:55.271868",
     "exception": false,
     "start_time": "2023-04-09T13:32:54.968921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot count pairs using all_df for the column \"Fare Interval\" and \"Fare (grouped by survival)\" with \"Survived\" as hue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78a93b",
   "metadata": {
    "papermill": {
     "duration": 0.043148,
     "end_time": "2023-04-09T13:32:56.548549",
     "exception": false,
     "start_time": "2023-04-09T13:32:56.505401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Process names\n",
    "\n",
    "\n",
    "When we process names, we would like to extract the following information:\n",
    "\n",
    "- Family name - this is the first word (or few first words, if a family name with multiple names), followed by a comma  \n",
    "- Title - this follows just after the comma   \n",
    "- Given name - this is the word or group of words following family name  \n",
    "- Maiden name - for ladies, is given between parantheses  \n",
    "\n",
    "We start with creating a function that parses the Name string and extract (if possible) these 4 elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "037ae626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:56.638681Z",
     "iopub.status.busy": "2023-04-09T13:32:56.637779Z",
     "iopub.status.idle": "2023-04-09T13:32:56.646591Z",
     "shell.execute_reply": "2023-04-09T13:32:56.645693Z"
    },
    "papermill": {
     "duration": 0.056439,
     "end_time": "2023-04-09T13:32:56.649198",
     "exception": false,
     "start_time": "2023-04-09T13:32:56.592759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: also move this function to a separate file\n",
    "def parse_names(row):\n",
    "    try:\n",
    "        text = row[\"Name\"]\n",
    "        split_text = text.split(\",\")\n",
    "        family_name = split_text[0]\n",
    "        next_text = split_text[1]\n",
    "        split_text = next_text.split(\".\")\n",
    "        title = (split_text[0] + \".\").lstrip().rstrip()\n",
    "        next_text = split_text[1]\n",
    "        if \"(\" in next_text:\n",
    "            split_text = next_text.split(\"(\")\n",
    "            given_name = split_text[0]\n",
    "            maiden_name = split_text[1].rstrip(\")\")\n",
    "            return pd.Series([family_name, title, given_name, maiden_name])\n",
    "        else:\n",
    "            given_name = next_text\n",
    "            return pd.Series([family_name, title, given_name, None])\n",
    "    except Exception as ex:\n",
    "        print(f\"Exception: {ex}\")\n",
    "    \n",
    "def parse_names(row):\n",
    "    \"\"\"\n",
    "    Parse the 'Name' field of a DataFrame row to extract family name, title,\n",
    "    given name, and maiden name.\n",
    "\n",
    "    Parameters:\n",
    "    row (pd.Series): A row of the DataFrame containing the 'Name' column.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A Series containing family name, title, given name, and maiden name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = row[\"Name\"]\n",
    "        split_text = text.split(\",\")\n",
    "        family_name = split_text[0].strip()\n",
    "        next_text = split_text[1]\n",
    "        split_text = next_text.split(\".\")\n",
    "        title = (split_text[0] + \".\").strip()\n",
    "        next_text = split_text[1].strip()\n",
    "\n",
    "        if \"(\" in next_text:\n",
    "            split_text = next_text.split(\"(\")\n",
    "            given_name = split_text[0].strip()\n",
    "            maiden_name = split_text[1].rstrip(\")\").strip()\n",
    "            return pd.Series([family_name, title, given_name, maiden_name])\n",
    "        else:\n",
    "            given_name = next_text\n",
    "            return pd.Series([family_name, title, given_name, None])\n",
    "    except Exception as ex:\n",
    "        print(f\"Exception: {ex}\")\n",
    "        return pd.Series([None, None, None, None])  # Return None for all if an error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7205ec96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:56.738979Z",
     "iopub.status.busy": "2023-04-09T13:32:56.738089Z",
     "iopub.status.idle": "2023-04-09T13:32:57.144625Z",
     "shell.execute_reply": "2023-04-09T13:32:57.143365Z"
    },
    "papermill": {
     "duration": 0.455038,
     "end_time": "2023-04-09T13:32:57.147656",
     "exception": false,
     "start_time": "2023-04-09T13:32:56.692618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "all_df[[\"Family Name\", \"Title\", \"Given Name\", \"Maiden Name\"]] = all_df.apply(lambda row: parse_names(row), axis=1)\n",
    "\n",
    "def extract_names(df):\n",
    "    \"\"\"\n",
    "    Extract family name, title, given name, and maiden name from the 'Name' column \n",
    "    and add them as new columns to the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the 'Name' column.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with new columns added for Family Name, Title, \n",
    "                  Given Name, and Maiden Name.\n",
    "    \"\"\"\n",
    "    # Apply the parse_names function to extract name components\n",
    "    df[[\"Family Name\", \"Title\", \"Given Name\", \"Maiden Name\"]] = df.apply(lambda row: parse_names(row), axis=1)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# all_df = extract_names(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e19eab27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:32:57.236073Z",
     "iopub.status.busy": "2023-04-09T13:32:57.235614Z",
     "iopub.status.idle": "2023-04-09T13:32:57.407505Z",
     "shell.execute_reply": "2023-04-09T13:32:57.406264Z"
    },
    "papermill": {
     "duration": 0.219965,
     "end_time": "2023-04-09T13:32:57.410708",
     "exception": false,
     "start_time": "2023-04-09T13:32:57.190743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "train_df[[\"Family Name\", \"Title\", \"Given Name\", \"Maiden Name\"]] = train_df.apply(lambda row: parse_names(row), axis=1)\n",
    "\n",
    "def extract_names_from_train(df):\n",
    "    \"\"\"\n",
    "    Extract family name, title, given name, and maiden name from the 'Name' column \n",
    "    of the training DataFrame and add them as new columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The training DataFrame containing the 'Name' column.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The original DataFrame with new columns added for Family Name, Title, \n",
    "                  Given Name, and Maiden Name.\n",
    "    \"\"\"\n",
    "    # Apply the parse_names function to extract name components\n",
    "    df[[\"Family Name\", \"Title\", \"Given Name\", \"Maiden Name\"]] = df.apply(lambda row: parse_names(row), axis=1)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# train_df = extract_names_from_train(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ebda5",
   "metadata": {
    "papermill": {
     "duration": 0.086205,
     "end_time": "2023-04-09T13:33:04.669504",
     "exception": false,
     "start_time": "2023-04-09T13:33:04.583299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Multivariate analysis\n",
    "\n",
    "\n",
    "Let's look now to the interaction of multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6f99b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:05.296837Z",
     "iopub.status.busy": "2023-04-09T13:33:05.295977Z",
     "iopub.status.idle": "2023-04-09T13:33:05.576799Z",
     "shell.execute_reply": "2023-04-09T13:33:05.575541Z"
    },
    "papermill": {
     "duration": 0.370555,
     "end_time": "2023-04-09T13:33:05.579497",
     "exception": false,
     "start_time": "2023-04-09T13:33:05.208942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Plot count pairs of \"Age Interval\" grouped by \"Pclass\"\n",
    "\n",
    "def plot_age_interval_by_pclass(df):\n",
    "    \"\"\"\n",
    "    Plot count of 'Age Interval' grouped by 'Pclass'.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing 'Age Interval' and 'Pclass' columns.\n",
    "    \"\"\"\n",
    "    # Group by 'Pclass' and 'Age Interval' and count occurrences\n",
    "    count_data = df.groupby(['Pclass', 'Age Interval']).size().reset_index(name='Count')\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Pclass', y='Count', hue='Age Interval', data=count_data, palette='viridis')\n",
    "    \n",
    "    # Adding title and labels\n",
    "    plt.title('Count of Age Intervals by Passenger Class')\n",
    "    plt.xlabel('Passenger Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Age Interval')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_age_interval_by_pclass(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edd4521f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:06.183187Z",
     "iopub.status.busy": "2023-04-09T13:33:06.182486Z",
     "iopub.status.idle": "2023-04-09T13:33:06.473029Z",
     "shell.execute_reply": "2023-04-09T13:33:06.472178Z"
    },
    "papermill": {
     "duration": 0.382551,
     "end_time": "2023-04-09T13:33:06.475270",
     "exception": false,
     "start_time": "2023-04-09T13:33:06.092719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Plot count pairs of \"Age Interval\" grouped by \"Embarked\"\n",
    "\n",
    "def plot_age_interval_by_embarked(df):\n",
    "    \"\"\"\n",
    "    Plot count of 'Age Interval' grouped by 'Embarked'.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing 'Age Interval' and 'Embarked' columns.\n",
    "    \"\"\"\n",
    "    # Group by 'Embarked' and 'Age Interval' and count occurrences\n",
    "    count_data = df.groupby(['Embarked', 'Age Interval']).size().reset_index(name='Count')\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Embarked', y='Count', hue='Age Interval', data=count_data, palette='viridis')\n",
    "    \n",
    "    # Adding title and labels\n",
    "    plt.title('Count of Age Intervals by Embarkation Point')\n",
    "    plt.xlabel('Embarkation Point')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Age Interval')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_age_interval_by_embarked(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ed6af14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:06.653514Z",
     "iopub.status.busy": "2023-04-09T13:33:06.652512Z",
     "iopub.status.idle": "2023-04-09T13:33:06.921452Z",
     "shell.execute_reply": "2023-04-09T13:33:06.920271Z"
    },
    "papermill": {
     "duration": 0.36104,
     "end_time": "2023-04-09T13:33:06.924241",
     "exception": false,
     "start_time": "2023-04-09T13:33:06.563201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Plot count pairs of \"Pclass\" grouped by \"Fare Interval\"\n",
    "\n",
    "def plot_pclass_by_fare_interval(df):\n",
    "    \"\"\"\n",
    "    Plot count of 'Pclass' grouped by 'Fare Interval'.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing 'Pclass' and 'Fare Interval' columns.\n",
    "    \"\"\"\n",
    "    # Group by 'Fare Interval' and 'Pclass' and count occurrences\n",
    "    count_data = df.groupby(['Fare Interval', 'Pclass']).size().reset_index(name='Count')\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Fare Interval', y='Count', hue='Pclass', data=count_data, palette='viridis')\n",
    "    \n",
    "    # Adding title and labels\n",
    "    plt.title('Count of Passenger Class by Fare Interval')\n",
    "    plt.xlabel('Fare Interval')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Pclass')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_pclass_by_fare_interval(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6cfde",
   "metadata": {
    "papermill": {
     "duration": 0.094321,
     "end_time": "2023-04-09T13:33:12.087427",
     "exception": false,
     "start_time": "2023-04-09T13:33:11.993106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Few more engineered data \n",
    "\n",
    "\n",
    "Let's create two more engineered features:  \n",
    "* Family size interval: Single, Small, Large  \n",
    "* Aggregated titles: Mr, Mrs, Master, Miss, and Rare  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8750f33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:12.286324Z",
     "iopub.status.busy": "2023-04-09T13:33:12.285408Z",
     "iopub.status.idle": "2023-04-09T13:33:12.292210Z",
     "shell.execute_reply": "2023-04-09T13:33:12.291252Z"
    },
    "papermill": {
     "duration": 0.108468,
     "end_time": "2023-04-09T13:33:12.294946",
     "exception": false,
     "start_time": "2023-04-09T13:33:12.186478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Family Size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Family Size'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: turn into function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [all_df, train_df]:\n\u001b[0;32m----> 3\u001b[0m     dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFamily Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFamily Size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Family Size'"
     ]
    }
   ],
   "source": [
    "# TODO: turn into function\n",
    "for dataset in [all_df, train_df]:\n",
    "    dataset[\"Family Type\"] = dataset[\"Family Size\"]\n",
    "\n",
    "def add_family_type_column(datasets):\n",
    "    \"\"\"\n",
    "    Add a 'Family Type' column based on 'Family Size' to the provided datasets.\n",
    "\n",
    "    Parameters:\n",
    "    datasets (list of pd.DataFrame): List containing DataFrames to which the 'Family Type' column will be added.\n",
    "    \"\"\"\n",
    "    for dataset in datasets:\n",
    "        # Check if 'Family Size' exists in the dataset\n",
    "        if \"Family Size\" in dataset.columns:\n",
    "            dataset[\"Family Type\"] = dataset[\"Family Size\"]\n",
    "        else:\n",
    "            print(f\"'Family Size' column not found in dataset with shape {dataset.shape}.\")\n",
    "\n",
    "# Example usage:\n",
    "# add_family_type_column([all_df, train_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "084b0171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:12.491821Z",
     "iopub.status.busy": "2023-04-09T13:33:12.490955Z",
     "iopub.status.idle": "2023-04-09T13:33:12.503269Z",
     "shell.execute_reply": "2023-04-09T13:33:12.502125Z"
    },
    "papermill": {
     "duration": 0.113944,
     "end_time": "2023-04-09T13:33:12.505983",
     "exception": false,
     "start_time": "2023-04-09T13:33:12.392039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Family Size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Family Size'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: turn into function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [all_df, train_df]:\n\u001b[0;32m----> 3\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFamily Size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFamily Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mloc[(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFamily Size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFamily Size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFamily Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmall\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m     dataset\u001b[38;5;241m.\u001b[39mloc[(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFamily Size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFamily Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLarge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Family Size'"
     ]
    }
   ],
   "source": [
    "# TODO: turn into function\n",
    "for dataset in [all_df, train_df]:\n",
    "    dataset.loc[dataset[\"Family Size\"] == 1, \"Family Type\"] = \"Single\"\n",
    "    dataset.loc[(dataset[\"Family Size\"] > 1) & (dataset[\"Family Size\"] < 5), \"Family Type\"] = \"Small\"\n",
    "    dataset.loc[(dataset[\"Family Size\"] >= 5), \"Family Type\"] = \"Large\"\n",
    "\n",
    "def assign_family_type(datasets):\n",
    "    \"\"\"\n",
    "    Assign a 'Family Type' based on 'Family Size' for the provided datasets.\n",
    "\n",
    "    Parameters:\n",
    "    datasets (list of pd.DataFrame): List containing DataFrames to which the 'Family Type' will be assigned.\n",
    "    \"\"\"\n",
    "    for dataset in datasets:\n",
    "        # Assign 'Family Type' based on 'Family Size'\n",
    "        dataset.loc[dataset[\"Family Size\"] == 1, \"Family Type\"] = \"Single\"\n",
    "        dataset.loc[(dataset[\"Family Size\"] > 1) & (dataset[\"Family Size\"] < 5), \"Family Type\"] = \"Small\"\n",
    "        dataset.loc[dataset[\"Family Size\"] >= 5, \"Family Type\"] = \"Large\"\n",
    "\n",
    "# Example usage:\n",
    "# assign_family_type([all_df, train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e24ae982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:12.699667Z",
     "iopub.status.busy": "2023-04-09T13:33:12.699264Z",
     "iopub.status.idle": "2023-04-09T13:33:12.705377Z",
     "shell.execute_reply": "2023-04-09T13:33:12.704166Z"
    },
    "papermill": {
     "duration": 0.105912,
     "end_time": "2023-04-09T13:33:12.707971",
     "exception": false,
     "start_time": "2023-04-09T13:33:12.602059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dataset in [all_df, train_df]:\n",
    "    dataset[\"Titles\"] = dataset[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc8828dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:12.901887Z",
     "iopub.status.busy": "2023-04-09T13:33:12.901436Z",
     "iopub.status.idle": "2023-04-09T13:33:12.916334Z",
     "shell.execute_reply": "2023-04-09T13:33:12.915297Z"
    },
    "papermill": {
     "duration": 0.115339,
     "end_time": "2023-04-09T13:33:12.918779",
     "exception": false,
     "start_time": "2023-04-09T13:33:12.803440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Titles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Titles'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: turn into function\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [all_df, train_df]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#unify `Miss`\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitles\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMlle.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiss.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitles\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitles\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMs.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiss.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#unify `Mrs`\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Titles'"
     ]
    }
   ],
   "source": [
    "# TODO: turn into function\n",
    "for dataset in [all_df, train_df]:\n",
    "    #unify `Miss`\n",
    "    dataset['Titles'] = dataset['Titles'].replace('Mlle.', 'Miss.')\n",
    "    dataset['Titles'] = dataset['Titles'].replace('Ms.', 'Miss.')\n",
    "    #unify `Mrs`\n",
    "    dataset['Titles'] = dataset['Titles'].replace('Mme.', 'Mrs.')\n",
    "    # unify Rare\n",
    "    dataset['Titles'] = dataset['Titles'].replace(['Lady.', 'the Countess.','Capt.', 'Col.',\\\n",
    "     'Don.', 'Dr.', 'Major.', 'Rev.', 'Sir.', 'Jonkheer.', 'Dona.'], 'Rare')\n",
    "    \n",
    "def unify_titles(datasets):\n",
    "    \"\"\"\n",
    "    Standardize titles in the 'Titles' column for the provided datasets.\n",
    "\n",
    "    Parameters:\n",
    "    datasets (list of pd.DataFrame): List containing DataFrames to which the title unification will be applied.\n",
    "    \"\"\"\n",
    "    for dataset in datasets:\n",
    "        # Unify 'Miss'\n",
    "        dataset['Titles'] = dataset['Titles'].replace({'Mlle.': 'Miss.', 'Ms.': 'Miss.'})\n",
    "        # Unify 'Mrs'\n",
    "        dataset['Titles'] = dataset['Titles'].replace({'Mme.': 'Mrs.'})\n",
    "        # Unify Rare titles\n",
    "        rare_titles = ['Lady.', 'the Countess.', 'Capt.', 'Col.', 'Don.', \n",
    "                       'Dr.', 'Major.', 'Rev.', 'Sir.', 'Jonkheer.', 'Dona.']\n",
    "        dataset['Titles'] = dataset['Titles'].replace(rare_titles, 'Rare')\n",
    "\n",
    "# Example usage:\n",
    "# unify_titles([all_df, train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "086e07cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:13.120113Z",
     "iopub.status.busy": "2023-04-09T13:33:13.118894Z",
     "iopub.status.idle": "2023-04-09T13:33:13.136189Z",
     "shell.execute_reply": "2023-04-09T13:33:13.135227Z"
    },
    "papermill": {
     "duration": 0.120346,
     "end_time": "2023-04-09T13:33:13.138472",
     "exception": false,
     "start_time": "2023-04-09T13:33:13.018126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Titles'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: turn into function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSurvived\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitles\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m], as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#### \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_survival_rate_by_title_and_sex\u001b[39m(dataset):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/titanic_project/lib/python3.9/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Titles'] not in index\""
     ]
    }
   ],
   "source": [
    "# TODO: turn into function\n",
    "train_df[['Titles', 'Sex', 'Survived']].groupby(['Titles', 'Sex'], as_index=False).mean()\n",
    "\n",
    "#### \n",
    "def calculate_survival_rate_by_title_and_sex(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the mean survival rate grouped by 'Titles' and 'Sex'.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (pd.DataFrame): The DataFrame containing the relevant columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with the mean survival rates grouped by 'Titles' and 'Sex'.\n",
    "    \"\"\"\n",
    "    return dataset[['Titles', 'Sex', 'Survived']].groupby(['Titles', 'Sex'], as_index=False).mean()\n",
    "\n",
    "# Example usage:\n",
    "# survival_rates = calculate_survival_rate_by_title_and_sex(train_df)\n",
    "# print(survival_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7c474",
   "metadata": {
    "papermill": {
     "duration": 0.10356,
     "end_time": "2023-04-09T13:33:15.043186",
     "exception": false,
     "start_time": "2023-04-09T13:33:14.939626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864616e1",
   "metadata": {
    "papermill": {
     "duration": 0.10099,
     "end_time": "2023-04-09T13:33:16.010380",
     "exception": false,
     "start_time": "2023-04-09T13:33:15.909390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature engineering: Map categorical value to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d8a725d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:16.211769Z",
     "iopub.status.busy": "2023-04-09T13:33:16.211320Z",
     "iopub.status.idle": "2023-04-09T13:33:16.220279Z",
     "shell.execute_reply": "2023-04-09T13:33:16.219412Z"
    },
    "papermill": {
     "duration": 0.113535,
     "end_time": "2023-04-09T13:33:16.222534",
     "exception": false,
     "start_time": "2023-04-09T13:33:16.108999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "for dataset in [train_df, test_df]:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "\n",
    "def map_sex_column(datasets):\n",
    "    \"\"\"\n",
    "    Maps the 'Sex' column to integers, where 'female' is 1 and 'male' is 0.\n",
    "\n",
    "    Parameters:\n",
    "    datasets (list of pd.DataFrame): List of DataFrames to apply the transformation.\n",
    "\n",
    "    Returns:\n",
    "    None: The function modifies the DataFrames in place.\n",
    "    \"\"\"\n",
    "    for dataset in datasets:\n",
    "        dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
    "\n",
    "# Example usage:\n",
    "# map_sex_column([train_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635df80",
   "metadata": {
    "papermill": {
     "duration": 0.101154,
     "end_time": "2023-04-09T13:33:16.423406",
     "exception": false,
     "start_time": "2023-04-09T13:33:16.322252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create train-validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "328c85e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:16.632663Z",
     "iopub.status.busy": "2023-04-09T13:33:16.631240Z",
     "iopub.status.idle": "2023-04-09T13:33:16.640631Z",
     "shell.execute_reply": "2023-04-09T13:33:16.639695Z"
    },
    "papermill": {
     "duration": 0.116133,
     "end_time": "2023-04-09T13:33:16.643139",
     "exception": false,
     "start_time": "2023-04-09T13:33:16.527006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VALID_SIZE = 0.2\n",
    "train, valid = train_test_split(train_df, test_size=VALID_SIZE, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7756ef",
   "metadata": {
    "papermill": {
     "duration": 0.0982,
     "end_time": "2023-04-09T13:33:16.839581",
     "exception": false,
     "start_time": "2023-04-09T13:33:16.741381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define predictor features and target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb90547e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:17.044342Z",
     "iopub.status.busy": "2023-04-09T13:33:17.043685Z",
     "iopub.status.idle": "2023-04-09T13:33:17.049206Z",
     "shell.execute_reply": "2023-04-09T13:33:17.048067Z"
    },
    "papermill": {
     "duration": 0.11164,
     "end_time": "2023-04-09T13:33:17.051579",
     "exception": false,
     "start_time": "2023-04-09T13:33:16.939939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictors = [\"Sex\", \"Pclass\"]\n",
    "target = 'Survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b02c9f",
   "metadata": {
    "papermill": {
     "duration": 0.099538,
     "end_time": "2023-04-09T13:33:17.252933",
     "exception": false,
     "start_time": "2023-04-09T13:33:17.153395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define the training and validation data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1f8b2807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:17.456588Z",
     "iopub.status.busy": "2023-04-09T13:33:17.455330Z",
     "iopub.status.idle": "2023-04-09T13:33:17.463172Z",
     "shell.execute_reply": "2023-04-09T13:33:17.462210Z"
    },
    "papermill": {
     "duration": 0.113017,
     "end_time": "2023-04-09T13:33:17.465660",
     "exception": false,
     "start_time": "2023-04-09T13:33:17.352643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: turn into function\n",
    "train_X = train[predictors]\n",
    "train_Y = train[target].values\n",
    "valid_X = valid[predictors]\n",
    "valid_Y = valid[target].values\n",
    "\n",
    "def prepare_datasets(train, valid, predictors, target):\n",
    "    \"\"\"\n",
    "    Prepares the training and validation datasets by extracting the feature columns (predictors) and the target column.\n",
    "\n",
    "    Parameters:\n",
    "    train (pd.DataFrame): The training dataset.\n",
    "    valid (pd.DataFrame): The validation dataset.\n",
    "    predictors (list of str): List of column names to be used as predictors/features.\n",
    "    target (str): The column name of the target variable.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Returns four datasets: train_X, train_Y, valid_X, valid_Y.\n",
    "    \"\"\"\n",
    "    # Extract feature columns and target columns for training\n",
    "    train_X = train[predictors]\n",
    "    train_Y = train[target].values\n",
    "\n",
    "    # Extract feature columns and target columns for validation\n",
    "    valid_X = valid[predictors]\n",
    "    valid_Y = valid[target].values\n",
    "\n",
    "    return train_X, train_Y, valid_X, valid_Y\n",
    "\n",
    "# Example usage:\n",
    "# train_X, train_Y, valid_X, valid_Y = prepare_datasets(train_df, valid_df, predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2d827",
   "metadata": {
    "papermill": {
     "duration": 0.098654,
     "end_time": "2023-04-09T13:33:17.664113",
     "exception": false,
     "start_time": "2023-04-09T13:33:17.565459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initialize the classifiction algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f9324151",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:17.865542Z",
     "iopub.status.busy": "2023-04-09T13:33:17.864275Z",
     "iopub.status.idle": "2023-04-09T13:33:17.870039Z",
     "shell.execute_reply": "2023-04-09T13:33:17.869160Z"
    },
    "papermill": {
     "duration": 0.109141,
     "end_time": "2023-04-09T13:33:17.872379",
     "exception": false,
     "start_time": "2023-04-09T13:33:17.763238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: could this and the following code cells be turned into a function that returns the prediction?\n",
    "clf = RandomForestClassifier(n_jobs=-1, \n",
    "                             random_state=42,\n",
    "                             criterion=\"gini\",\n",
    "                             n_estimators=100,\n",
    "                             verbose=False)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_and_predict_random_forest(train_X, train_Y, valid_X, random_state=42, n_estimators=100, criterion=\"gini\"):\n",
    "    \"\"\"\n",
    "    Trains a RandomForestClassifier on the training data and returns predictions for both training and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    train_X (pd.DataFrame): Features of the training dataset.\n",
    "    train_Y (pd.Series or np.array): Target of the training dataset.\n",
    "    valid_X (pd.DataFrame): Features of the validation dataset.\n",
    "    random_state (int, optional): Random state for reproducibility. Default is 42.\n",
    "    n_estimators (int, optional): The number of trees in the forest. Default is 100.\n",
    "    criterion (str, optional): The function to measure the quality of a split. Default is \"gini\".\n",
    "\n",
    "    Returns:\n",
    "    tuple: Returns predictions for both training and validation sets.\n",
    "    \"\"\"\n",
    "    # Initialize the RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_jobs=-1, \n",
    "                                 random_state=random_state,\n",
    "                                 criterion=criterion,\n",
    "                                 n_estimators=n_estimators,\n",
    "                                 verbose=False)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(train_X, train_Y)\n",
    "\n",
    "    # Predict on the training and validation data\n",
    "    preds_train = clf.predict(train_X)\n",
    "    preds_valid = clf.predict(valid_X)\n",
    "\n",
    "    return preds_train, preds_valid\n",
    "\n",
    "# Example usage:\n",
    "# preds_train, preds_valid = train_and_predict_random_forest(train_X, train_Y, valid_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642506e1",
   "metadata": {
    "papermill": {
     "duration": 0.099258,
     "end_time": "2023-04-09T13:33:18.070446",
     "exception": false,
     "start_time": "2023-04-09T13:33:17.971188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Fit the classifier with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d8e0e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:18.277424Z",
     "iopub.status.busy": "2023-04-09T13:33:18.276277Z",
     "iopub.status.idle": "2023-04-09T13:33:18.539778Z",
     "shell.execute_reply": "2023-04-09T13:33:18.538462Z"
    },
    "papermill": {
     "duration": 0.373025,
     "end_time": "2023-04-09T13:33:18.542770",
     "exception": false,
     "start_time": "2023-04-09T13:33:18.169745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc9595",
   "metadata": {
    "papermill": {
     "duration": 0.10132,
     "end_time": "2023-04-09T13:33:18.747232",
     "exception": false,
     "start_time": "2023-04-09T13:33:18.645912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Predict the train data (to check the training classification error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9a3bbc8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:18.953760Z",
     "iopub.status.busy": "2023-04-09T13:33:18.952358Z",
     "iopub.status.idle": "2023-04-09T13:33:19.062149Z",
     "shell.execute_reply": "2023-04-09T13:33:19.060880Z"
    },
    "papermill": {
     "duration": 0.21616,
     "end_time": "2023-04-09T13:33:19.065029",
     "exception": false,
     "start_time": "2023-04-09T13:33:18.848869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_tr = clf.predict(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b61af6",
   "metadata": {
    "papermill": {
     "duration": 0.099136,
     "end_time": "2023-04-09T13:33:19.263660",
     "exception": false,
     "start_time": "2023-04-09T13:33:19.164524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Predict the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fa28974c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:19.467958Z",
     "iopub.status.busy": "2023-04-09T13:33:19.466546Z",
     "iopub.status.idle": "2023-04-09T13:33:19.577062Z",
     "shell.execute_reply": "2023-04-09T13:33:19.575465Z"
    },
    "papermill": {
     "duration": 0.217366,
     "end_time": "2023-04-09T13:33:19.580249",
     "exception": false,
     "start_time": "2023-04-09T13:33:19.362883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = clf.predict(valid_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994312c",
   "metadata": {
    "papermill": {
     "duration": 0.099652,
     "end_time": "2023-04-09T13:33:19.781425",
     "exception": false,
     "start_time": "2023-04-09T13:33:19.681773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "## Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62963993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:19.985235Z",
     "iopub.status.busy": "2023-04-09T13:33:19.983841Z",
     "iopub.status.idle": "2023-04-09T13:33:19.996204Z",
     "shell.execute_reply": "2023-04-09T13:33:19.994526Z"
    },
    "papermill": {
     "duration": 0.117754,
     "end_time": "2023-04-09T13:33:19.998936",
     "exception": false,
     "start_time": "2023-04-09T13:33:19.881182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(train_Y, preds_tr, target_names=['Not Survived', 'Survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fcb4f1",
   "metadata": {
    "papermill": {
     "duration": 0.100623,
     "end_time": "2023-04-09T13:33:20.206904",
     "exception": false,
     "start_time": "2023-04-09T13:33:20.106281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Classification report for validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55f853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T13:33:20.409841Z",
     "iopub.status.busy": "2023-04-09T13:33:20.409379Z",
     "iopub.status.idle": "2023-04-09T13:33:20.421171Z",
     "shell.execute_reply": "2023-04-09T13:33:20.419836Z"
    },
    "papermill": {
     "duration": 0.115487,
     "end_time": "2023-04-09T13:33:20.423620",
     "exception": false,
     "start_time": "2023-04-09T13:33:20.308133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(valid_Y, preds, target_names=['Not Survived', 'Survived']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.560621,
   "end_time": "2023-04-09T13:33:21.452362",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-09T13:32:31.891741",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
